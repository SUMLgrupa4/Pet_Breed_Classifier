---
title: Pet Breed Classifier
emoji: ğŸ¾
colorFrom: blue
colorTo: purple
sdk: streamlit
sdk_version: 1.28.0
app_file: app.py
pinned: false
license: mit
python_version: "3.9"
---

# Pet Breed Classifier ğŸ¾

A machine learning model that classifies pet breeds from images using AutoGluon and Streamlit. This project includes a complete CI/CD pipeline for automated training and deployment to Hugging Face Spaces.

## ğŸš€ Features

- **23 Pet Breeds**: Classify popular dog and cat breeds
- **High Accuracy**: 92.54% overall accuracy
- **Fast Inference**: Real-time predictions with confidence scores
- **Beautiful UI**: Modern Streamlit interface
- **CI/CD Pipeline**: Automated training and deployment
- **Training Results**: Confusion matrix, classification reports, and model analysis

## ğŸ“Š Model Performance

- **Overall Accuracy**: 92.54%
- **Average Precision**: 0.92
- **Average Recall**: 0.91
- **Average F1-Score**: 0.91
- **Supported Breeds**: 23 (Dogs & Cats)

## ğŸ› ï¸ Technologies

- **AutoGluon**: Multi-modal deep learning framework
- **Streamlit**: Web application framework
- **Python 3.9+**: Core programming language
- **GitHub Actions**: CI/CD automation
- **Hugging Face Spaces**: Model deployment platform

## ğŸ“ Project Structure

```
Pet_Breed_Classifier-master/
â”œâ”€â”€ .github/workflows/          # CI/CD workflows
â”‚   â”œâ”€â”€ deploy.yml              # Main deployment workflow
â”‚   â””â”€â”€ train-only.yml          # Training-only workflow
â”œâ”€â”€ scripts/                    # Training scripts
â”‚   â”œâ”€â”€ preprocess.py           # Data preprocessing
â”‚   â”œâ”€â”€ train_model.py          # Model training
â”‚   â””â”€â”€ validate_model.py       # Model validation
â”œâ”€â”€ models/                     # Trained models
â”œâ”€â”€ outputs/                    # Training results
â”‚   â”œâ”€â”€ confusion_matrix.png    # Confusion matrix visualization
â”‚   â”œâ”€â”€ classification_report.txt
â”‚   â”œâ”€â”€ model_analysis.txt
â”‚   â””â”€â”€ final_assessment.txt
â”œâ”€â”€ app.py                      # Web application
â”œâ”€â”€ run_pipeline.py             # Complete training pipeline
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ docker-compose.yml          # Docker configuration
â”œâ”€â”€ Dockerfile                  # Docker image
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Quick Start

### Local Development

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd Pet_Breed_Classifier-master
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Add your training data**
   ```
   data/
   â”œâ”€â”€ images/                  # Your pet images
   â””â”€â”€ metadata/                # Labels and metadata
   ```

4. **Run the training pipeline**
   ```bash
   python run_pipeline.py
   ```

5. **Launch the Streamlit app**
   ```bash
   streamlit run app.py
   ```

### Docker Deployment

```bash
# Build and run with Docker Compose
docker-compose up --build

# Or run with Docker directly
docker build -t pet-breed-classifier .
docker run -p 8501:8501 pet-breed-classifier
```

### CI/CD Deployment

#### Prerequisites

1. **GitHub Repository**: Push your code to GitHub
2. **Hugging Face Account**: Create an account at [huggingface.co](https://huggingface.co)
3. **Hugging Face Token**: Generate a token with write permissions
4. **Docker Hub Account**: Create an account at [hub.docker.com](https://hub.docker.com)

#### Setup Steps

1. **Add GitHub Secrets**
   - Go to your GitHub repository â†’ Settings â†’ Secrets and variables â†’ Actions
   - Add the following secrets:
     - `HF_TOKEN`: Your Hugging Face token
     - `DOCKER_USERNAME`: Your Docker Hub username
     - `DOCKER_PASSWORD`: Your Docker Hub password/token

2. **Trigger Deployment**
   - **Automatic**: Push to `main` or `master` branch
   - **Manual**: Go to Actions tab â†’ "Continuous Integration" â†’ Run workflow
   - **Training Only**: Go to Actions tab â†’ "Train Model Only" â†’ Run workflow

3. **Access Your App**
   - Your app will be available at: `https://huggingface.co/spaces/<your-username>/pet-breed-classifier`

### Docker-Based CI Pipeline

The project now includes a comprehensive Docker-based CI pipeline that:

1. **Fetches Training Data**: Downloads the pet breed dataset from Hugging Face
2. **Builds Training Image**: Creates a Docker image with all training dependencies
3. **Runs Training Pipeline**: Executes the complete training pipeline in a containerized environment
4. **Builds Production Image**: Creates a production-ready image with the trained model
5. **Pushes to Registry**: Registers both training and production images to Docker Hub
6. **Deploys to Hugging Face**: Deploys the application with the latest model

#### Data Fetching

The CI pipeline automatically fetches training data from Hugging Face datasets:

```bash
# Fetch data manually
make fetch-data

# Or run the script directly
python scripts/fetch_data.py
```

The data fetching script:
- Attempts to load from multiple possible dataset names
- Falls back to creating a sample dataset if the main dataset is unavailable
- Creates the proper directory structure expected by the training pipeline
- Generates the label mapping file automatically

#### Docker Images

- **Training Image** (`pet-breed-classifier:training-data`): Contains all dependencies for model training
- **Production Image** (`pet-breed-classifier:latest`): Optimized for serving the trained model

#### Local Docker Training

```bash
# Fetch data and build training image
make fetch-data
make docker-build-training

# Run training pipeline
make docker-train-ci

# Or use docker-compose for training
make docker-train-compose
```

#### Docker Registry Integration

The CI pipeline automatically:
- Builds and pushes training images to Docker Hub
- Tags images with appropriate versions
- Maintains separate images for training and production
- Ensures reproducible training environments

## ğŸ“ˆ Training Results

After each training run, the following artifacts are generated:

### ğŸ“Š Confusion Matrix
- Visual representation of model predictions vs actual labels
- Helps identify which breeds are most/least accurately classified

### ğŸ“‹ Classification Report
- Detailed per-class metrics (precision, recall, F1-score)
- Overall accuracy and macro/micro averages

### ğŸ“ Model Analysis
- Model size and complexity analysis
- Training time and resource usage

### âœ… Final Assessment
- Summary of model performance
- Deployment readiness evaluation

## ğŸ”§ Configuration

### Training Parameters
Edit `pipeline_config.py` to customize:
- Model architecture
- Training hyperparameters
- Data preprocessing settings
- Validation split ratios

### CI/CD Settings
Modify `.github/workflows/deploy.yml` to:
- Change deployment triggers
- Adjust resource allocation
- Customize deployment settings

## ğŸ“± Using the App

1. **Upload Image**: Click "Browse files" to upload a pet image
2. **Get Prediction**: Click "Classify Breed" for instant results
3. **View Results**: See breed prediction with confidence score
4. **Check Performance**: Navigate to "Model Info" for detailed metrics

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- AutoGluon team for the excellent multi-modal framework
- Streamlit for the beautiful web app framework
- Hugging Face for providing free model hosting
- The open-source community for inspiration and support

---

**Built with â¤ï¸ using AutoGluon & Streamlit**

*For questions or support, please open an issue on GitHub.* 